### Directly request to LM Studio

POST http://127.0.0.1:1234/v1/chat/completions
Content-Type: application/json
Authorization: Bearer sk-xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx

{
  "model": "liquid/lfm2-1.2b",
  "messages": [
    {
      "role": "user",
      "content": "How does streaming with an OpenAI /v1/chat/completions endpoint work?"
    }
  ]
}

### Request through the proxy

POST http://127.0.0.1:5601/lmstudio/v1/chat/completions
Content-Type: application/json
Authorization: Bearer sk-xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx

{
  "model": "liquid/lfm2-1.2b",
  "messages": [
    {
      "role": "user",
      "content": "How does streaming with an OpenAI /v1/chat/completions endpoint work?"
    }
  ]
}

### Streaming request through the proxy

POST http://127.0.0.1:5601/lmstudio/v1/chat/completions
Content-Type: application/json
Authorization: Bearer sk-xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx

{
  "model": "liquid/lfm2-1.2b",
  "messages": [
    {
      "role": "user",
      "content": "How does streaming with an OpenAI /v1/chat/completions endpoint work?"
    }
  ],
  "stream": true
}

### Get list of models

GET http://127.0.0.1:5601/lmstudio/v1/models
Authorization: Bearer sk-xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx

### Unknown route test (404)

GET http://127.0.0.1:5601/unknown/test
Authorization: Bearer sk-xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx